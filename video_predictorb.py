import streamlit as st
import cv2
import numpy as np
import moviepy.editor as mp
from PIL import Image
import torch
import torch.nn as nn
from datetime import datetime

# æ¨¡æ‹ŸAIé¢„æµ‹æ¨¡å‹
class SimplePredictor:
    def __init__(self):
        # æ¨¡æ‹Ÿè®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°
        self.weights = {
            'duration': -0.2,
            'brightness': 0.3,
            'motion': 0.4,
            'audio_volume': 0.1
        }
    
    def predict(self, features):
        score = sum(features[k]*self.weights[k] for k in self.weights)
        return min(max(score*100, 0), 100)  # ç¡®ä¿åˆ†æ•°åœ¨0-100ä¹‹é—´

# è§†é¢‘åˆ†æå‡½æ•°
def analyze_video(video_path):
    # åŸºç¡€åˆ†æ
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    
    # äº®åº¦åˆ†æ
    success, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    brightness = np.mean(gray)
    
    # è¿åŠ¨æ£€æµ‹
    ret, next_frame = cap.read()
    diff = cv2.absdiff(frame, next_frame)
    motion = np.mean(diff)
    
    # éŸ³é¢‘åˆ†æ
    clip = mp.VideoFileClip(video_path)
    audio = clip.audio
    volume = np.mean(np.abs(audio.to_soundarray()))
    
    return {
        "duration": duration,
        "brightness": brightness,
        "motion": motion,
        "audio_volume": volume
    }

# ç”Ÿæˆä¼˜åŒ–å»ºè®®
def get_suggestions(result):
    suggestions = []
    if result['duration'] > 60:
        suggestions.append("âš ï¸ è§†é¢‘è¿‡é•¿ï¼ˆå»ºè®®30ç§’å†…ï¼‰")
    if result['brightness'] < 100:
        suggestions.append("ğŸŒŸ æé«˜ç”»é¢äº®åº¦")
    if result['motion'] < 20:
        suggestions.append("ğŸ¬ å¢åŠ é•œå¤´è¿åŠ¨")
    return suggestions

# ç•Œé¢å¸ƒå±€
st.set_page_config(page_title="çŸ­è§†é¢‘çˆ†æ¬¾æ£€æµ‹å™¨", layout="wide")
st.title("ğŸ¬ ä¸€é”®æ£€æµ‹è§†é¢‘çˆ†æ¬¾æ¦‚ç‡")

# ä¸Šä¼ è§†é¢‘
uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„çŸ­è§†é¢‘ï¼ˆMP4æ ¼å¼ï¼‰", type=["mp4"])

if uploaded_file:
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    with open("temp_video.mp4", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # æ˜¾ç¤ºè§†é¢‘
    st.video("temp_video.mp4")
    
    # åˆ†æè§†é¢‘
    with st.spinner('æ­£åœ¨åˆ†æè§†é¢‘...'):
        analysis = analyze_video("temp_video.mp4")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    st.subheader("ğŸ“Š è§†é¢‘ä½“æ£€æŠ¥å‘Š")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ—¶é•¿ï¼ˆç§’ï¼‰", round(analysis['duration'], 1))
    with col2:
        st.metric("ç”»é¢äº®åº¦", int(analysis['brightness']))
    with col3:
        st.metric("åŠ¨æ€å¼ºåº¦", int(analysis['motion']))
    
    # é¢„æµ‹å¾—åˆ†
    predictor = SimplePredictor()
    score = predictor.predict(analysis)
    
    # æ˜¾ç¤ºè¯„åˆ†
    st.subheader("ğŸ”¥ çˆ†æ¬¾æŒ‡æ•°")
    st.progress(score/100)
    st.write(f"ç»¼åˆè¯„åˆ†ï¼š{score:.1f}åˆ†ï¼ˆæ»¡åˆ†100ï¼‰")
    
    # ä¼˜åŒ–å»ºè®®
    st.subheader("ğŸ’¡ ä¼˜åŒ–æŒ‡å—")
    for suggestion in get_suggestions(analysis):
        st.error(suggestion)
    
    # å‘å¸ƒæ—¶é—´å»ºè®®
    st.subheader("â° æœ€ä½³å‘å¸ƒæ—¶é—´")
    st.success("æ¨èå‘å¸ƒæ—¶é—´ï¼šæ™šä¸Š7ç‚¹-9ç‚¹ï¼ˆæ ¹æ®å¹³å°ç”¨æˆ·æ´»è·ƒæ—¶æ®µï¼‰")

st.markdown("---")
st.caption("æç¤ºï¼šæœ¬ç»“æœä¸ºæ¨¡æ‹Ÿé¢„æµ‹ï¼Œå®é™…æ•ˆæœéœ€ç»“åˆå†…å®¹è´¨é‡")